# -*- coding: utf-8 -*-
"""Adversarial_learning_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ud2kGEvoUyCmFVLM5crJUywQH3xtvF_b
"""

import math
import scipy.io
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.utils import Sequence
from datetime import timedelta
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
import numpy as np
import pandas as pd
import time
import os
from tensorflow.keras.layers.experimental import preprocessing
import matplotlib.pyplot as plt
from tensorflow.keras.utils import to_categorical
from tensorflow.keras import backend as K
from tensorflow.keras.layers import RNN
from tensorflow.python.ops import array_ops
from tensorflow.python.keras import activations
from tensorflow.python.keras import initializers
import scipy.io
from tensorflow.python.keras.layers import Input
from sklearn import preprocessing
from tensorflow.keras.layers.experimental import preprocessing
import matplotlib.pyplot as plt

data_mmwave_aug = scipy.io.loadmat('data_mmwave_aug.mat')
data_mmwave_aug = data_mmwave_aug['data_mmwave_aug']
#data_mmwave = preprocessing.normalize(data_mmwave)
np.random.shuffle(data_mmwave_aug)
x_data_train_1 = data_mmwave_aug[:1200,:-1,:]
y_data_train_1 = data_mmwave_aug[:1200,-1,:2]
target_train_label_1 = np.full((1200,1),0)

x_data_test_1 = data_mmwave_aug[1200:,:-1,:]
y_data_test_1 = data_mmwave_aug[1200:,-1,:2]
target_test_label_1 = np.full((300,1),0)

data_mmwave_aug = scipy.io.loadmat('data_mmwave_aug_1.mat')
data_mmwave_aug = data_mmwave_aug['data_mmwave_aug']
#data_mmwave = preprocessing.normalize(data_mmwave)
np.random.shuffle(data_mmwave_aug)
x_data_train_2 = data_mmwave_aug[:1200,:-1,:]
y_data_train_2 = data_mmwave_aug[:1200,-1,:2]
target_train_label_2 = np.full((1200,1),1)

x_data_test_2 = data_mmwave_aug[1200:,:-1,:]
y_data_test_2 = data_mmwave_aug[1200:,-1,:2]
target_test_label_2 = np.full((300,1),1)

data_mmwave_aug = scipy.io.loadmat('data_mmwave_aug_2.mat')
data_mmwave_aug = data_mmwave_aug['data_mmwave_aug']
#data_mmwave = preprocessing.normalize(data_mmwave)
np.random.shuffle(data_mmwave_aug)
x_data_train_3 = data_mmwave_aug[:1200,:-1,:]
y_data_train_3 = data_mmwave_aug[:1200,-1,:2]
target_train_label_3 = np.full((1200,1),2)

x_data_test_3 = data_mmwave_aug[1200:,:-1,:]
y_data_test_3 = data_mmwave_aug[1200:,-1,:2]
target_test_label_3 = np.full((300,1),2)



data_mmwave_aug = scipy.io.loadmat('data_mmwave_aug_5.mat')
data_mmwave_aug = data_mmwave_aug['data_mmwave_aug'][:720,:,:]
print(data_mmwave_aug.shape)
#data_mmwave = preprocessing.normalize(data_mmwave)
x_data_test_cros = data_mmwave_aug[:,:-1,:]
y_data_test_cros = data_mmwave_aug[:,-1,:2]
target_train_label_4 = np.full((720,1),3)
#x_data_test_cros = np.tile(x_data_test_cros,(2,1,1))
#y_data_test_cros = np.tile(y_data_test_cros,(2,1))
print(y_data_test_cros.shape)

x_data_train = np.concatenate((x_data_train_1,x_data_train_2,x_data_train_3,x_data_test_cros),axis=0)
y_data_train = np.concatenate((y_data_train_1,y_data_train_2,y_data_train_3,y_data_test_cros),axis=0)
target_train_label = np.concatenate((target_train_label_1,target_train_label_2,target_train_label_3,target_train_label_4),axis=0)
target_train_label = to_categorical(target_train_label)
target_train_label.shape

x_data_test = np.concatenate((x_data_test_1,x_data_test_2,x_data_test_3),axis=0)
y_data_test = np.concatenate((y_data_test_1,y_data_test_2,y_data_test_3),axis=0)

x_data_train_sin = x_data_train.copy()
y_data_train_sin = y_data_train.copy()
x_data_train_sin[:,:,:2] = np.sin(x_data_train[:,:,:2]/180*math.pi)
y_data_train_sin[:,:] = np.sin(y_data_train[:,:]/180*math.pi)

x_data_test_sin = x_data_test.copy()
y_data_test_sin = y_data_test.copy()
x_data_test_sin[:,:,:2] = np.sin(x_data_test[:,:,:2]/180*math.pi)
y_data_test_sin[:,:] = np.sin(y_data_test[:,:]/180*math.pi)


x_data_test_cros_sin = x_data_test_cros.copy()
y_data_test_cros_sin = y_data_test_cros.copy()
x_data_test_cros_sin[:,:,:2] = np.sin(x_data_test_cros[:,:,:2]/180*math.pi)
y_data_test_cros_sin[:,:] = np.sin(y_data_test_cros[:,:]/180*math.pi)

class m_LSTM(keras.layers.Layer):

    def __init__(self, units, activation='tanh', recurrent_activation='hard_sigmoid',
                 use_bias=True,bias_initializer='zeros',
               unit_forget_bias=True,**kwargs):
        self.units = units
        self.state_size = [units, units]
        self.output_size = self.units
        self.activation = activations.get(activation)
        self.recurrent_activation = activations.get(recurrent_activation)

        self.bias_initializer = initializers.get(bias_initializer)

        self.use_bias = use_bias
        self.unit_forget_bias = unit_forget_bias

        #self.state_size = [tf.TensorShape([self.units]),tf.TensorShape([self.units])]
        super(m_LSTM, self).__init__(**kwargs)

    def build(self, input_shape):
        #default_caching_device = _caching_device(self)
        input_dim = input_shape[-1]
        self.kernel = self.add_weight(shape=(input_dim, self.units*4),
                                      initializer='uniform',
                                      name='kernel')
        self.ctm1_kernel = self.add_weight(shape=( self.units,self.units),
                                      initializer='uniform',
                                      name='ctm1_kernel')
        self.recurrent_kernel = self.add_weight(
            shape=(self.units, self.units*4),
            initializer='uniform',
            name='recurrent_kernel')
        self.built = True

        if self.use_bias:

          if self.unit_forget_bias:
            def bias_initializer(_, *args, **kwargs):
              return K.concatenate([
              self.bias_initializer((self.units,), *args, **kwargs),
              initializers.get('ones')((self.units,), *args, **kwargs),
              self.bias_initializer((self.units * 3,), *args, **kwargs),])
          else:
            bias_initializer = self.bias_initializer
          
          self.bias = self.add_weight(shape=(self.units * 5,),name='bias',
          initializer=bias_initializer)

        else:
          self.bias = None
        self.built = True


    def _compute_carry_and_output(self, x, h_tm1, c_tm1):
        """Computes carry and output using split kernels."""
        x_i, x_f, x_c, x_o = x
        h_tm1_i, h_tm1_f, h_tm1_c, h_tm1_o = h_tm1
        i = self.recurrent_activation(x_i + K.dot(h_tm1_i, self.recurrent_kernel[:, :self.units]))
        f = self.recurrent_activation(x_f + K.dot(h_tm1_f, self.recurrent_kernel[:, self.units:self.units * 2]))
        c = f * c_tm1 + i * self.activation(x_c + K.dot(h_tm1_c, self.recurrent_kernel[:, self.units * 2:self.units * 3]))
        o = self.recurrent_activation(x_o + K.dot(h_tm1_o, self.recurrent_kernel[:, self.units * 3:]))
        return c, o

    def call(self, inputs, states):
        
        #inputs = inputs[:,:-1]
        #print("input size", inputs)
        h_tm1 = states[0]
        c_tm1 = states[1]

        inputs_i = inputs
        inputs_f = inputs
        inputs_c = inputs
        inputs_o = inputs

        k_i, k_f, k_c, k_o = array_ops.split(self.kernel, num_or_size_splits=4, axis=1)
        #print("k_i size", k_i)

        x_i = K.dot(inputs_i[:,:-1], k_i[:-1,:])
        x_f = K.dot(inputs_f[:,:-1], k_f[:-1,:])
        x_c = K.dot(inputs_c[:,:-1], k_c[:-1,:])
        x_o = K.dot(inputs_o[:,:-1], k_o[:-1,:])
        
        k_d = self.ctm1_kernel
        c_ts = K.dot(c_tm1,k_d)
      
        if self.use_bias:
          b_i, b_f, b_c, b_o,b_d = array_ops.split(self.bias, num_or_size_splits=5, axis=0)
          #print("b_i size", b_i)
          x_i = K.bias_add(x_i, b_i)
          x_f = K.bias_add(x_f, b_f)
          x_c = K.bias_add(x_c, b_c)
          x_o = K.bias_add(x_o, b_o)
          c_ts = K.bias_add(c_ts, b_d)
      
      
        #######modify long term######
        #c_l = tf.math.divide_no_nan(c_tm1 - c_ts,inputs[0,-1])
        c_l = tf.math.divide(c_tm1 - c_ts,inputs[0,-1]*10000)
        c_tm1 = c_l + c_ts
       
        #print("c_tm1 aaafter", c_tm1)
        

        h_tm1_i = h_tm1
        h_tm1_f = h_tm1
        h_tm1_c = h_tm1
        h_tm1_o = h_tm1

        x = (x_i, x_f, x_c, x_o)
        h_tm1 = (h_tm1_i, h_tm1_f, h_tm1_c, h_tm1_o)

        c, o = self._compute_carry_and_output(x, h_tm1, c_tm1)
        #print("c size", c)
        #h = K.dot(inputs, self.kernel)
        #output = h + K.dot(h_tm1, self.recurrent_kernel)

        h = o * self.activation(c)
        return h, [h,c]
    def get_config(self):
        config = {
        'units':
            self.units,
        'activation':
            activations.serialize(self.activation),
        'recurrent_activation':
            activations.serialize(self.recurrent_activation),
        'use_bias':
            self.use_bias,
        'bias_initializer':
            initializers.serialize(self.bias_initializer),
        'unit_forget_bias':
            self.unit_forget_bias,
        }
        config.update(_config_for_enable_caching_device(self))
        base_config = super(LSTMCell, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))

def make_feature_extractor_model():
    nor_layer = preprocessing.Normalization(axis=2)
    nor_layer.adapt(x_data_train)
    ######model #########

    ts_inputs = tf.keras.Input(shape=(None, 3))
    x= nor_layer(ts_inputs)
    z = layers.Conv1D(12,4,activation='relu',padding='causal')(x[:,:,:-1])
    y = layers.Concatenate(axis=-1)([z, x[:,:,2:3]])
    model = tf.keras.Model(inputs=ts_inputs , outputs=y)
    return model

feature_extractor = make_feature_extractor_model()

def make_beam_prediction_model():
    cell = m_LSTM(64)
    layer = RNN(cell)
    ######model #########

    ts_inputs = tf.keras.Input(shape=(None,13))
    x = layer(ts_inputs)
    y = layers.Dense(2, activation='linear')(x)

    model = tf.keras.Model(inputs=ts_inputs , outputs=y)
    #model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),
     #         loss=tf.keras.losses.MeanSquaredError(),
    #          metrics=['mse'])
    return model

def make_discriminator_model():
    cell = m_LSTM(64)
    layer = RNN(cell)
    ######model #########

    ts_inputs = tf.keras.Input(shape=(None,13))
    x = layer(ts_inputs)
    x = layers.Dense(4, activation='linear')(x)
    y = layers.Activation('softmax')(x)
    model = tf.keras.Model(inputs=ts_inputs , outputs=y)

    return model

discriminator = make_discriminator_model()
#target_decision = discriminator(generated_image)
beam_prediction =  make_beam_prediction_model()
#y_estimation = act_recogize(generated_image)

def discriminator_loss(real_output,real_label):
    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)
    total_loss = cce(real_label,real_output)
    return total_loss
#discriminator_loss(target_decision,target_label)

#def feature_extractor_loss(real_output):
#    cce = tf.keras.losses.CategoricalCrossentropy()
#    total_loss = cce(tf.ones_like(real_output),real_output)
#    return total_loss
#generator_loss(target_decision)

def beam_prediction_loss(real_output,truth_value):
    mse = tf.keras.losses.MeanSquaredError()
    total_loss = mse(truth_value,real_output)
    return total_loss
#act_recognize_loss(y_estimation,y_truth)

feature_extractor_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)
discriminator_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)
beam_prediction_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)

#@tf.function
def train_step(his_beam,target_label,truth_value):
    #noise = tf.random.normal([BATCH_SIZE, noise_dim])

    with tf.GradientTape() as fea_tape, tf.GradientTape() as disc_tape, tf.GradientTape() as beam_tape:
      generated_features = feature_extractor (his_beam, training=True)
      target_decision = discriminator(generated_features, training=True)
      y_estimation = beam_prediction(generated_features, training=True)

      #feature_extractor_loss = feature_extractor_loss(target_decision)
      disc_loss = discriminator_loss(target_decision,target_label)
      beam_loss = beam_prediction_loss(y_estimation,truth_value)
      feature_extractor_loss = -disc_loss+0.2*beam_loss

    gradients_of_feature_extractor = fea_tape.gradient( feature_extractor_loss, feature_extractor.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)
    gradients_of_beam = beam_tape.gradient(beam_loss, beam_prediction.trainable_variables)

    feature_extractor_optimizer.apply_gradients(zip(gradients_of_feature_extractor, feature_extractor.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))
    beam_prediction_optimizer.apply_gradients(zip(gradients_of_beam, beam_prediction.trainable_variables))

    print("feature_extractor_loss",feature_extractor_loss)
    print("disc_loss",disc_loss)
    print("beam_loss",beam_loss)

for i in range(40):
  train_step(x_data_train,target_train_label,y_data_train)

generated_features = feature_extractor(x_data_test_cros[:,:,:])
result_adv = beam_prediction(generated_features).numpy()