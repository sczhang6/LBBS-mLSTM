# -*- coding: utf-8 -*-
"""mLSTM_single user.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16jKpEY-UG2wSuDlUyU52EZXzugTeLRMJ
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
from tensorflow import keras
from tensorflow.keras import backend as K
from tensorflow.keras.layers import RNN
import tensorflow as tf
import numpy as np
from tensorflow.python.ops import array_ops
from tensorflow.python.keras import activations
from tensorflow.python.keras import initializers
from keras.layers import Lambda
import scipy.io
from tensorflow.keras import layers
from tensorflow.python.keras.layers import Input
from sklearn import preprocessing
from tensorflow.keras.layers.experimental import preprocessing
import math
import matplotlib.pyplot as plt

data_mmwave = scipy.io.loadmat('data_mmwave_aug.mat')
data_mmwave = data_mmwave['data_mmwave_aug']
#data_mmwave = preprocessing.normalize(data_mmwave)
np.random.shuffle(data_mmwave)
x_data_train = data_mmwave[:1200,:-1,:]
y_data_train = data_mmwave[:1200,-1,:2]

x_data_test = data_mmwave[1200:,:-1,:]
y_data_test = data_mmwave[1200:,-1,:2]

'''data_mmwave_aug = scipy.io.loadmat('data_mmwave_aug_1.mat')
data_mmwave_aug = data_mmwave_aug['data_mmwave_aug']
np.random.shuffle(data_mmwave_aug)
x_data_train_1 = data_mmwave_aug[:1200,:-1,:]
y_data_train_1 = data_mmwave_aug[:1200,-1,:2]
x_data_test_1 = data_mmwave_aug[1200:,:-1,:]
y_data_test_1 = data_mmwave_aug[1200:,-1,:2]

data_mmwave_aug = scipy.io.loadmat('data_mmwave_aug_2.mat')
data_mmwave_aug = data_mmwave_aug['data_mmwave_aug']
np.random.shuffle(data_mmwave_aug)
x_data_train_2 = data_mmwave_aug[:1200,:-1,:]
y_data_train_2 = data_mmwave_aug[:1200,-1,:2]
x_data_test_2 = data_mmwave_aug[1200:,:-1,:]
y_data_test_2 = data_mmwave_aug[1200:,-1,:2]

data_mmwave_aug = scipy.io.loadmat('data_mmwave_aug_3.mat')
data_mmwave_aug = data_mmwave_aug['data_mmwave_aug']
np.random.shuffle(data_mmwave_aug)
x_data_train_3 = data_mmwave_aug[:1200,:-1,:]
y_data_train_3 = data_mmwave_aug[:1200,-1,:2]
x_data_test_3 = data_mmwave_aug[1200:,:-1,:]
y_data_test_3 = data_mmwave_aug[1200:,-1,:2]

data_mmwave_aug = scipy.io.loadmat('data_mmwave_aug_5.mat')
data_mmwave_aug = data_mmwave_aug['data_mmwave_aug']
np.random.shuffle(data_mmwave_aug)
x_data_train_4 = data_mmwave_aug[:1200,:-1,:]
y_data_train_4 = data_mmwave_aug[:1200,-1,:2]
x_data_test_cros = data_mmwave_aug[1200:,:-1,:]
y_data_test_cros = data_mmwave_aug[1200:,-1,:2]

x_data_train = np.concatenate((x_data_train, x_data_train_1,x_data_train_2,x_data_train_3,x_data_train_4),axis=0)
y_data_train = np.concatenate((y_data_train, y_data_train_1,y_data_train_2,y_data_train_3,y_data_train_4),axis=0)

x_data_test = np.concatenate((x_data_test,x_data_test_1,x_data_test_2,x_data_test_3),axis=0)
y_data_test = np.concatenate((y_data_test, y_data_test_1,y_data_test_2,y_data_test_3),axis=0)'''

class m_LSTM(keras.layers.Layer):

    def __init__(self, units, activation='tanh', recurrent_activation='hard_sigmoid',
                 use_bias=True,bias_initializer='zeros',
               unit_forget_bias=True,**kwargs):
        self.units = units
        self.state_size = [units, units]

        self.activation = activations.get(activation)
        self.recurrent_activation = activations.get(recurrent_activation)

        self.bias_initializer = initializers.get(bias_initializer)

        self.use_bias = use_bias
        self.unit_forget_bias = unit_forget_bias

        #self.state_size = [tf.TensorShape([self.units]),tf.TensorShape([self.units])]
        super(m_LSTM, self).__init__(**kwargs)

    def build(self, input_shape):
        self.kernel = self.add_weight(shape=(input_shape[-1], self.units*4),
                                      initializer='uniform',
                                      name='kernel')
        self.ctm1_kernel = self.add_weight(shape=( self.units,self.units),
                                      initializer='uniform',
                                      name='ctm1_kernel')
        self.recurrent_kernel = self.add_weight(
            shape=(self.units, self.units*4),
            initializer='uniform',
            name='recurrent_kernel')
        self.built = True

        if self.use_bias:

          if self.unit_forget_bias:
            def bias_initializer(_, *args, **kwargs):
              return K.concatenate([
              self.bias_initializer((self.units,), *args, **kwargs),
              initializers.get('ones')((self.units,), *args, **kwargs),
              self.bias_initializer((self.units * 3,), *args, **kwargs),])
          else:
            bias_initializer = self.bias_initializer
          
          self.bias = self.add_weight(shape=(self.units * 5,),name='bias',
          initializer=bias_initializer)

        else:
          self.bias = None
        self.built = True


    def _compute_carry_and_output(self, x, h_tm1, c_tm1):
        """Computes carry and output using split kernels."""
        x_i, x_f, x_c, x_o = x
        h_tm1_i, h_tm1_f, h_tm1_c, h_tm1_o = h_tm1
        i = self.recurrent_activation(x_i + K.dot(h_tm1_i, self.recurrent_kernel[:, :self.units]))
        f = self.recurrent_activation(x_f + K.dot(h_tm1_f, self.recurrent_kernel[:, self.units:self.units * 2]))
        c = f * c_tm1 + i * self.activation(x_c + K.dot(h_tm1_c, self.recurrent_kernel[:, self.units * 2:self.units * 3]))
        o = self.recurrent_activation(x_o + K.dot(h_tm1_o, self.recurrent_kernel[:, self.units * 3:]))
        return c, o

    def call(self, inputs, states):
        h_tm1 = states[0]
        c_tm1 = states[1]

        inputs_i = inputs
        inputs_f = inputs
        inputs_c = inputs
        inputs_o = inputs

        k_i, k_f, k_c, k_o = array_ops.split(self.kernel, num_or_size_splits=4, axis=1)
        

        x_i = K.dot(inputs_i[:,:-1], k_i[:-1,:])
        x_f = K.dot(inputs_f[:,:-1], k_f[:-1,:])
        x_c = K.dot(inputs_c[:,:-1], k_c[:-1,:])
        x_o = K.dot(inputs_o[:,:-1], k_o[:-1,:])
        
        k_d = self.ctm1_kernel
        c_ts = K.dot(c_tm1,k_d)

        if self.use_bias:
          b_i, b_f, b_c, b_o, b_d = array_ops.split(self.bias, num_or_size_splits=5, axis=0)
          x_i = K.bias_add(x_i, b_i)
          x_f = K.bias_add(x_f, b_f)
          x_c = K.bias_add(x_c, b_c)
          x_o = K.bias_add(x_o, b_o)
          c_ts = K.bias_add(c_ts, b_d)
        
        
        #######modify long term######
        c_l = tf.math.divide(c_tm1 - c_ts,inputs[0,-1]*10000)
        c_tm1 = c_l + c_ts
        
        h_tm1_i = h_tm1
        h_tm1_f = h_tm1
        h_tm1_c = h_tm1
        h_tm1_o = h_tm1

        x = (x_i, x_f, x_c, x_o)
        h_tm1 = (h_tm1_i, h_tm1_f, h_tm1_c, h_tm1_o)

        c, o = self._compute_carry_and_output(x, h_tm1, c_tm1)

        h = o * self.activation(c)
        return h, [h,c]

# T_LSTM Model
cell = m_LSTM(64)
mlstm_layer = RNN(cell)
nor_layer = preprocessing.Normalization(axis=2)
nor_layer.adapt(data_mmwave)
######model #########
ts_inputs = tf.keras.Input(shape=(None, 3))
x= nor_layer(ts_inputs)
z = layers.Conv1D(12,4,activation='relu',padding='causal')(x[:,:,:-1])
x = layers.Concatenate(axis=-1)([z, x[:,:,2:3]])
x = mlstm_layer(x)
y = layers.Dense(2, activation='relu')(x)
model_t = tf.keras.Model(inputs=ts_inputs , outputs=y)
model_t.summary()

model_t.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),
              loss=tf.keras.losses.MeanSquaredError(),
              metrics=['mse'])

model_t.fit(x_data_train, y_data_train,batch_size=300,epochs=30, validation_data=(x_data_test, y_data_test))

result_t = model_t.predict(x_data_test)

